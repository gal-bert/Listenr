# NYHM

![Platforms](https://img.shields.io/badge/platform-iOS-lightgrey.svg)
[![Swift Version](https://img.shields.io/badge/Swift-5-F16D39.svg?style=flat)](https://developer.apple.com/swift)

## About
iOS app that help the hearing-impaired to consume content / live event where closed captions are unavailable.

### Why we want to help?
*  The unavailability of Closed Captions
*  Hard to multitask between lip reading and note taking
*  Lip reading is not applicable in some situation
*  The hearing-impaired can receive nearly equal information 

### Our solution concept
We will develop a native iOS App that **solves the difficulties of the hearing-impaired on receiving and staying focused on the media / content by  transcribing the verbally driven content to text in real-time** by **providing speech-to-text ability and saving the transcription to an exportable file.** This is a solution to the challenge because **our research shows that the hearing-impaired has a hassle in lip-reading and taking notes in the same time, especially when the speaker talks to fast, using masks, or not in sync with the visual (laggy video on teleconference).**

## Contributor
* [@albert](https://github.com/gal-bert)
* [@aria](https://github.com/aria20)
* [@eki](https://github.com/rizk19)
* [@hafizhMo](http://github.com/hafizhMo)
* [@karen](https://github.com/karennatalia)
* [@pujita](https://github.com/pujitan22)
